{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinhnv0901/student_project/blob/main/recommend_course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJb5Pyi6JY5N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeIjyBZ9J1hp",
        "outputId": "428fad3a-5307-4a0b-af7b-fa92ac6c1791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'student_project'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 40 (delta 3), reused 15 (delta 2), pack-reused 20\u001b[K\n",
            "Unpacking objects: 100% (40/40), 76.52 MiB | 10.15 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/Vinhnv0901/student_project.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHqr-AcBKD3i"
      },
      "outputs": [],
      "source": [
        "data_grade = pd.read_excel(\"/content/student_project/Education_dataset_V2/02.diem.xlsx\")\n",
        "data_inf = pd.read_excel(\"/content/student_project/Education_dataset_V2/01.sinhvien.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4-9rVgrRpPX"
      },
      "outputs": [],
      "source": [
        "data_inf = data_inf[['mssv', ' namsinh', ' gioitinh', ' noisinh', ' lopsh', ' khoa', ' hedt', ' khoahoc', ' chuyennganh2',' tinhtrang']]\n",
        "data_inf.columns = ['mssv', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'chuyennganh2','tinhtrang']\n",
        "data_grade = data_grade[['mssv', ' mamh', ' malop', ' sotc', ' namhoc', ' hocky', ' diem', ' trangthai', ' mamh_tt']]\n",
        "data_grade.columns = ['mssv', 'mamh', 'malop', 'sotc', 'namhoc', 'hocky', 'diem', 'trangthai', 'mamh_tt']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###merge student table and grade table"
      ],
      "metadata": {
        "id": "qNQ-Mle_OdlE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIrscSkbMFZ8"
      },
      "outputs": [],
      "source": [
        "data_merge = pd.merge(data_grade, data_inf, on = 'mssv', how = 'inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQpwzYkyQqyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479689bb-82c7-4e7b-8727-c57b3852cc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of nan value each columns: {'mssv': 2856, 'mamh': 2856, 'malop': 2856, 'sotc': 2856, 'namhoc': 2856, 'hocky': 2856, 'diem': 2891, 'trangthai': 2856, 'mamh_tt': 2856, 'namsinh': 2857, 'gioitinh': 2856, 'noisinh': 2856, 'lopsh': 2856, 'khoa': 2856, 'hedt': 2856, 'khoahoc': 2856, 'chuyennganh2': 2856, 'tinhtrang': 2856}\n"
          ]
        }
      ],
      "source": [
        "print('the number of nan value each columns:',{col: list(pd.isna(data_merge[col])).count(True) for col in data_merge.columns})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data cleaning"
      ],
      "metadata": {
        "id": "2Kv3I04BOr6c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x7AoJNjdi5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2f7042-2190-4bc3-ee2b-ac71b98da919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c7a6858c2d5e>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_merge['diem'] = data_merge['diem'].replace(' NULL', np.nan)#chuyển đổi NUll về nan để thêm giá trị\n",
            "<ipython-input-7-c7a6858c2d5e>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_merge['diem'] = data_merge['diem'].fillna(method = 'ffill')# thêm giá trị điểm có các dùng nan\n"
          ]
        }
      ],
      "source": [
        "data_merge = data_merge.dropna(subset = ['diem'])#xóa các dòng có giá trị nan trong cột điểm \n",
        "data_merge['diem'] = data_merge['diem'].replace(' NULL', np.nan)#chuyển đổi NUll về nan để thêm giá trị\n",
        "data_merge['diem'] = data_merge['diem'].fillna(method = 'ffill')# thêm giá trị điểm có các dùng nan\n",
        "data_merge = data_merge.astype(dtype = {'namhoc': np.int32, 'diem': np.float32})\n",
        "data_merge = data_merge.drop(data_merge[data_merge['namhoc'] == 2012].index)#xóa các dòng năm 2012 vì dữ liệu quá ít\n",
        "#khóa khoảng trắng các cột mamh, khoa, khoaMH\n",
        "data_merge['mamh'] = data_merge['mamh'].str.strip()\n",
        "data_merge['khoa'] = data_merge['khoa'].str.strip()\n",
        "data_merge = data_merge.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5yBBoIOJw1i"
      },
      "source": [
        "###dentify cate of course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofr0Dm5IfqFs"
      },
      "outputs": [],
      "source": [
        "#Xác định môn học thuộc khoa nào\n",
        "mamh = data_merge['mamh'].copy()\n",
        "for i in range(data_merge.shape[0]):\n",
        "  mamh[i] = mamh[i].translate(str.maketrans(\"\",\"\", '0123456789'))\n",
        "a = mamh.unique() #các mã môn học đại diện cho khoa quản lý\n",
        "b = ['MHKT', 'KTMT', 'HTTT', 'HTTT', 'PĐTĐH', 'BMTL', 'KHMT', 'PĐTĐH', 'HTTT', 'HTTT', 'BMAV', 'MMT&TT', 'CNPM', 'BMAV', 'HTTT', 'KTTT', 'HTTT', 'KTMT', 'CNPM', 'HTTT', 'HTTT', 'HTTT','HTTT', 'PĐTĐH', 'PĐTĐH'] # các khoa\n",
        "mamh.replace(to_replace = a, value = b, inplace = True)\n",
        "for i in range(data_merge.shape[0]):#các nhóm môn học có của cái đầu là 'IT' cần được điều chỉnh lại\n",
        "  ma = data_merge.loc[i,'mamh']\n",
        "  if ma == 'IT001' or ma == 'IT003' or ma == 'IT011' or ma == 'IT013':\n",
        "    mamh[i] = 'KHMT'\n",
        "  elif ma == 'IT002' or ma == 'IT008':\n",
        "    mamh[i] = 'CNPM'\n",
        "  elif ma == 'IT004':\n",
        "    mamh[i] = 'HTTT'\n",
        "  elif ma == 'IT005':\n",
        "    mamh[i] = 'MMT&TT'\n",
        "  elif ma == 'IT006' or ma == 'IT007' or ma =='IT010' or ma == 'IT012':\n",
        "    mamh[i] = 'KTMT'\n",
        "  elif ma == 'IT009':\n",
        "    mamh[i] = 'PĐTĐH'\n",
        "data_merge['KhoaMH'] = np.array(mamh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KCA94Kp06jS"
      },
      "outputs": [],
      "source": [
        "#Không rõ là học kỳ hè có nên xóa hay không vì nó chỉ chiếm 2 phần trăm trong dataset nên tạp thời xóa ở đây thay vì xóa từ đầu????????????????????????????????????????????\n",
        "data_merge = data_merge.drop(data_merge[data_merge['hocky'] == 3].index)#xóa các dòng chứa học kỳ hè vì nó chỉ chiếm 2% trong dataset\n",
        "data_merge = data_merge.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Divide train and test:\n",
        "##80% students train and 20% students test\n",
        "##recommend courses of two terms in 2016"
      ],
      "metadata": {
        "id": "JlnrFwni0in2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "listStudent = np.unique(data_merge['mssv'])\n",
        "student_train, student_test = train_test_split(listStudent, test_size=0.2, random_state=42)\n",
        "\n",
        "data_train = data_merge[data_merge['mssv'].isin(student_train)]\n",
        "data_test = data_merge[data_merge['mssv'].isin(student_test) & data_merge['namhoc'].isin([2013, 2014, 2015])]"
      ],
      "metadata": {
        "id": "AlQzAWTp0hq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywQtKLiXJ36N"
      },
      "source": [
        "###statistic courses in each cate of each student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrjfPLhqrDtY"
      },
      "outputs": [],
      "source": [
        "faculties = np.unique(b)#danh sách cách khoa\n",
        "enrInFac_train = pd.DataFrame(columns = faculties)#thống kê số môn đăng ký của các khoa của từng học sinh train\n",
        "enrInFac_test = pd.DataFrame(columns = faculties)#thống kê số môn đăng ký của các khoa của từng học sinh test\n",
        "def a_student(dataStudent, faculties):# hàm này dùng để thống kê số đăng ký từng khoa của một học sinh\n",
        "  count_enrolls = []\n",
        "  static = dataStudent['KhoaMH'].value_counts()\n",
        "  indexx = static.index\n",
        "  for i in faculties:\n",
        "    if i in indexx:\n",
        "      count_enrolls.append(static[i])\n",
        "    else:\n",
        "      count_enrolls.append(0)\n",
        "  return pd.Series(count_enrolls,index = faculties)\n",
        "\n",
        "#Train\n",
        "for i in student_train:\n",
        "  newRow = a_student(data_train[data_train['mssv'] == i], faculties)\n",
        "  enrInFac_train = enrInFac_train.append(newRow, ignore_index=True)\n",
        "enrInFac_train.insert(0,'mssv', student_train)\n",
        "\n",
        "#Test\n",
        "for i in student_test:\n",
        "  newRow = a_student(data_test[data_test['mssv'] == i], faculties)\n",
        "  enrInFac_test = enrInFac_test.append(newRow, ignore_index=True)\n",
        "enrInFac_test.insert(0,'mssv', student_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##cate of each student"
      ],
      "metadata": {
        "id": "YEogEPrd7CSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cateStudent = pd.DataFrame(columns=['khoa'])#đây là dữ liệu chưa khoa của từng học sinh\n",
        "for i in range(listStudent.shape[0]):\n",
        "  k = data_merge[data_merge['mssv'] == data_merge.loc[i,'mssv']].khoa.iloc[0]\n",
        "  row = pd.Series([k], index = ['khoa'])\n",
        "  cateStudent = cateStudent.append(row, ignore_index = True)\n",
        "cateStudent.index = listStudent"
      ],
      "metadata": {
        "id": "dzW48iVI61Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Interest Score\n",
        "\n",
        "$Sim_m(s,s') = λSim(s,s') + (1-λ)samemajor(s,s')$\n",
        "###Equation of Interest Score:\n",
        "$IS(s,c) = \\frac{\\sum_{s' \\in S_{s,k}} {I_{C_{s'}}}\\times sim_m(s,s')} {\\sum_{s' \\in S_{s,k}} \\times sim_m(s,s')}$"
      ],
      "metadata": {
        "id": "JBIkLy-35XMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------train\n",
        "nml_enrInFac_train = enrInFac_train.drop('mssv', axis = 1)\n",
        "nml_enrInFac_train.index = enrInFac_train['mssv']\n",
        "nml_enrInFac_train = nml_enrInFac_train + 1 #---------- evade divide zero -------\n",
        "#normalize by dividing max\n",
        "for i in range(nml_enrInFac_train.shape[0]):\n",
        "  maxx = max(nml_enrInFac_train.iloc[i])\n",
        "  nml_enrInFac_train.iloc[i] = round((nml_enrInFac_train.iloc[i]/maxx).astype(float),4)\n",
        "\n",
        "# P\n",
        "norm2_train = np.linalg.norm(nml_enrInFac_train.iloc[:].astype(float), axis=1)\n",
        "for i in range(norm2_train.shape[0]):\n",
        "  nml_enrInFac_train.iloc[i] = nml_enrInFac_train.iloc[i]/norm2_train[i]\n",
        "#student's faculty by 1. In contrast by 0\n",
        "samemajor_train = pd.DataFrame(0, index=student_train, columns=faculties)\n",
        "for i in range(student_train.shape[0]):\n",
        "  samemajor_train.loc[student_train[i],cateStudent.loc[student_train[i],'khoa']] = 1\n",
        "\n",
        "#-------------------------------test\n",
        "nml_enrInFac_test = enrInFac_test.drop('mssv', axis = 1)\n",
        "nml_enrInFac_test.index = enrInFac_test['mssv']\n",
        "nml_enrInFac_test = nml_enrInFac_test + 1 #---------- evade divide zero -------\n",
        "#normalize by dividing max\n",
        "for i in range(nml_enrInFac_test.shape[0]): \n",
        "  maxx = max(nml_enrInFac_test.iloc[i])\n",
        "  nml_enrInFac_test.iloc[i] = round((nml_enrInFac_test.iloc[i]/maxx).astype(float),4)\n",
        "\n",
        "# P\n",
        "norm2_test = np.linalg.norm(nml_enrInFac_test.iloc[:].astype(float), axis=1)\n",
        "for i in range(norm2_test.shape[0]):\n",
        "  norm = norm2_test[i]\n",
        "  if norm == 0:\n",
        "    norm = 1\n",
        "  nml_enrInFac_test.iloc[i] = nml_enrInFac_test.iloc[i]/norm\n",
        "\n",
        "#student's faculty by 1. In contrast by 0\n",
        "samemajor_test = pd.DataFrame(0, index=student_test, columns=faculties)\n",
        "for i in range(student_test.shape[0]):\n",
        "  samemajor_test.loc[student_test[i],cateStudent.loc[student_test[i],'khoa']] = 1\n",
        "\n",
        "\n",
        "lamda = 0.5 ########################chú ý thay đổi giá trị lamda cho phù hợp\n",
        "k = 7\n",
        "\n",
        "Sim = round((np.matmul(nml_enrInFac_test, nml_enrInFac_train.transpose())*lamda + np.matmul(samemajor_test, samemajor_train.transpose())*(1 - lamda)).astype(float),4)\n",
        "Sim.columns = student_train\n",
        "\n",
        "top_k = Sim.apply(lambda row: row.nlargest(k), axis=1)\n",
        "top_k_mssv = pd.DataFrame(0, index = student_test,columns = [i for i in range(k)])#top-k similar student code of s as neighbors\n",
        "for i in range(student_test.shape[0]):\n",
        "  count = 0\n",
        "  for j in range(top_k.shape[1]):\n",
        "    if not pd.isna(top_k.iloc[i,j]):\n",
        "      top_k_mssv.iloc[i,count] = top_k.iloc[i].index[j]\n",
        "      count +=1\n",
        "\n",
        "top_k_mssv = top_k_mssv.sort_values(by=0)\n",
        "\n",
        "def sum_k(k, mssv, Sim, I):\n",
        "  S = 0\n",
        "  for i in range(k):\n",
        "    S += (Sim.loc[mssv[i]]*I[i])\n",
        "  return S\n",
        "\n",
        "def check_enroll(mssv, data_train, mamh, courseCate):\n",
        "  if mamh not in courseCate:\n",
        "    return 0\n",
        "  condition = (data_train['mssv'] == mssv) & (data_train['mamh'] == mamh)\n",
        "  if condition.any():\n",
        "    return 1\n",
        "  return 0\n",
        "student_neighbour = top_k.columns#bỏ những học sinh không thuộc neighbour\n",
        "data_neighbour = data_train[data_train['mssv'].isin(student_neighbour)]\n",
        "data_neighbour = data_neighbour[['mssv', 'mamh','khoa']]\n",
        "courses = np.unique(data_neighbour['mamh'])\n",
        "\n",
        "IS = pd.DataFrame(0, index = student_test, columns = courses)\n",
        "I = [1 for i in range(k)]\n",
        "list_course = {}\n",
        "for i in faculties:\n",
        "  data = data_merge[data_merge['khoa'] == i]\n",
        "  list_course[i] = np.unique(data['mamh'])\n",
        "\n",
        "\n",
        "\n",
        "for i in range(student_test.shape[0]):\n",
        "  print(i)\n",
        "  for j in range(courses.shape[0]):\n",
        "    I_C = [check_enroll(i, data_neighbour, courses[j], list_course[cateStudent.loc[i].iloc[0]]) for i in top_k_mssv.iloc[i]]\n",
        "    sim_sum1 = sum_k(k, top_k_mssv.iloc[i], Sim.iloc[i],I_C)\n",
        "    sim_sum2 = sum_k(k, top_k_mssv.iloc[i], Sim.iloc[i],I)\n",
        "    IS.iloc[i,j] = round(sim_sum1/sim_sum2, 4)\n"
      ],
      "metadata": {
        "id": "rUAyzFJH5Zt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4837d826-94be-424c-fa7a-3be44333bf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-5178dbd06505>:45: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  Sim = round((np.matmul(nml_enrInFac_test, nml_enrInFac_train.transpose())*lamda + np.matmul(samemajor_test, samemajor_train.transpose())*(1 - lamda)).astype(float),4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "pWxh-fcQ7EOc",
        "outputId": "875f193b-36aa-4655-caba-59625d20b839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          F451D99AXPvAibaEXe+fPSOag5leTcWuR+r937fj  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4857   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4052   \n",
              "\n",
              "                                          6988D28AXPvAibaEXe9MSDlNDFbYdo3rYOhSopw2  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.9804   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.8878   \n",
              "\n",
              "                                          7E308531XPvAibaEXe879+AOg1gh8i58Q/VMq7RU  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4981   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4144   \n",
              "\n",
              "                                          DD10B95EXPvAibaEXe/PQrWCRBKWOUTASXEgaMpR  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4797   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4292   \n",
              "\n",
              "                                          4CD37F46XPvAibaEXe8ge2UHv4J4Byyo6uzLKM42  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.9201   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.8746   \n",
              "\n",
              "                                          CEF4F5F1XPvAibaEXe9ej2kTw4OUmtE+HmhDvEXe  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4662   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4339   \n",
              "\n",
              "                                          AB4D8F99XPvAibaEXe/YKN5ysyYL7EjErJAJK5l+  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.3526   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.2689   \n",
              "\n",
              "                                          D349E207XPvAibaEXe/aPLdUCtOgChkEtg7JE0Ca  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4715   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.3831   \n",
              "\n",
              "                                          C9CD6314XPvAibaEXe8LX4hhYKrFZr9FZE839SqA  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4885   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4104   \n",
              "\n",
              "                                          D78141E5XPvAibaEXe9j81k8MH0oJ4zch8KMTSfQ  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.3758   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.3020   \n",
              "\n",
              "                                          ...  \\\n",
              "mssv                                      ...   \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB  ...   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw  ...   \n",
              "\n",
              "                                          8B9DD5F1XPvAibaEXe/7VXm0xgXldIyNDzaf66fA  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4609   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4304   \n",
              "\n",
              "                                          6B917B37XPvAibaEXe/KMtCr6bHaurGMaIHnPyOQ  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.9446   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.8847   \n",
              "\n",
              "                                          C5F2150DXPvAibaEXe+tg0ae8qw/gtk+nFTaazYq  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4555   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4044   \n",
              "\n",
              "                                          EF5725B0XPvAibaEXe+cHxM5cHw4WonybFt5QicB  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4935   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.3904   \n",
              "\n",
              "                                          479E77A5XPvAibaEXe/PGAaNNWvbUNSidEr/n3m6  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.9676   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.8662   \n",
              "\n",
              "                                          496BA332XPvAibaEXe/9n4RXguPAYPE1qUnKCdpJ  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.9297   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.8922   \n",
              "\n",
              "                                          554BEAD4XPvAibaEXe9hSzSdeSAT0nKSX8+l/eSA  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.9759   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.8938   \n",
              "\n",
              "                                          382BCEACXPvAibaEXe8zjuWfAVBr9cQalpl5Q/IX  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4580   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4291   \n",
              "\n",
              "                                          DE84103AXPvAibaEXe8/V1eK05z0442dkLKXGv09  \\\n",
              "mssv                                                                                 \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4774   \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.3975   \n",
              "\n",
              "                                          CAF1ABCDXPvAibaEXe/7BYdCAEGEzTgdf8kcAw53  \n",
              "mssv                                                                                \n",
              "4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB                                    0.4552  \n",
              "0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw                                    0.4099  \n",
              "\n",
              "[2 rows x 3239 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e2eed4b-0421-40c2-9c13-d11e6af7e115\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F451D99AXPvAibaEXe+fPSOag5leTcWuR+r937fj</th>\n",
              "      <th>6988D28AXPvAibaEXe9MSDlNDFbYdo3rYOhSopw2</th>\n",
              "      <th>7E308531XPvAibaEXe879+AOg1gh8i58Q/VMq7RU</th>\n",
              "      <th>DD10B95EXPvAibaEXe/PQrWCRBKWOUTASXEgaMpR</th>\n",
              "      <th>4CD37F46XPvAibaEXe8ge2UHv4J4Byyo6uzLKM42</th>\n",
              "      <th>CEF4F5F1XPvAibaEXe9ej2kTw4OUmtE+HmhDvEXe</th>\n",
              "      <th>AB4D8F99XPvAibaEXe/YKN5ysyYL7EjErJAJK5l+</th>\n",
              "      <th>D349E207XPvAibaEXe/aPLdUCtOgChkEtg7JE0Ca</th>\n",
              "      <th>C9CD6314XPvAibaEXe8LX4hhYKrFZr9FZE839SqA</th>\n",
              "      <th>D78141E5XPvAibaEXe9j81k8MH0oJ4zch8KMTSfQ</th>\n",
              "      <th>...</th>\n",
              "      <th>8B9DD5F1XPvAibaEXe/7VXm0xgXldIyNDzaf66fA</th>\n",
              "      <th>6B917B37XPvAibaEXe/KMtCr6bHaurGMaIHnPyOQ</th>\n",
              "      <th>C5F2150DXPvAibaEXe+tg0ae8qw/gtk+nFTaazYq</th>\n",
              "      <th>EF5725B0XPvAibaEXe+cHxM5cHw4WonybFt5QicB</th>\n",
              "      <th>479E77A5XPvAibaEXe/PGAaNNWvbUNSidEr/n3m6</th>\n",
              "      <th>496BA332XPvAibaEXe/9n4RXguPAYPE1qUnKCdpJ</th>\n",
              "      <th>554BEAD4XPvAibaEXe9hSzSdeSAT0nKSX8+l/eSA</th>\n",
              "      <th>382BCEACXPvAibaEXe8zjuWfAVBr9cQalpl5Q/IX</th>\n",
              "      <th>DE84103AXPvAibaEXe8/V1eK05z0442dkLKXGv09</th>\n",
              "      <th>CAF1ABCDXPvAibaEXe/7BYdCAEGEzTgdf8kcAw53</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mssv</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4BC011B2XPvAibaEXe9iVChpJY9DITS7AYFLgUjB</th>\n",
              "      <td>0.4857</td>\n",
              "      <td>0.9804</td>\n",
              "      <td>0.4981</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.9201</td>\n",
              "      <td>0.4662</td>\n",
              "      <td>0.3526</td>\n",
              "      <td>0.4715</td>\n",
              "      <td>0.4885</td>\n",
              "      <td>0.3758</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4609</td>\n",
              "      <td>0.9446</td>\n",
              "      <td>0.4555</td>\n",
              "      <td>0.4935</td>\n",
              "      <td>0.9676</td>\n",
              "      <td>0.9297</td>\n",
              "      <td>0.9759</td>\n",
              "      <td>0.4580</td>\n",
              "      <td>0.4774</td>\n",
              "      <td>0.4552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0B431A01XPvAibaEXe87069oyWO+IS0M6kVzLXKw</th>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.8878</td>\n",
              "      <td>0.4144</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.8746</td>\n",
              "      <td>0.4339</td>\n",
              "      <td>0.2689</td>\n",
              "      <td>0.3831</td>\n",
              "      <td>0.4104</td>\n",
              "      <td>0.3020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4304</td>\n",
              "      <td>0.8847</td>\n",
              "      <td>0.4044</td>\n",
              "      <td>0.3904</td>\n",
              "      <td>0.8662</td>\n",
              "      <td>0.8922</td>\n",
              "      <td>0.8938</td>\n",
              "      <td>0.4291</td>\n",
              "      <td>0.3975</td>\n",
              "      <td>0.4099</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 3239 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e2eed4b-0421-40c2-9c13-d11e6af7e115')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e2eed4b-0421-40c2-9c13-d11e6af7e115 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e2eed4b-0421-40c2-9c13-d11e6af7e115');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Timing and popularity based Score"
      ],
      "metadata": {
        "id": "LSLO3NFtaaGK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2a4YDnf0RuV"
      },
      "source": [
        "###Xác định kỳ học của học sinh đó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF3IsKd8MIGz"
      },
      "outputs": [],
      "source": [
        "#Đầu tiên xác định xem sinh viên nhập học năm mấy\n",
        "khoaHoc = data_merge['khoahoc'].copy()\n",
        "lis = np.unique(khoaHoc)\n",
        "lis_replace = np.array([2013, 2014, 2015, 2016])\n",
        "khoaHoc.replace(to_replace = lis, value = lis_replace, inplace = True)\n",
        "data_merge['namNhapHoc'] = khoaHoc\n",
        "#Tính học kỳ của của từng đăng ký\n",
        "data_merge['soHocKy'] = (data_merge['namhoc'] - data_merge['namNhapHoc'])*2 + data_merge['hocky']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np1usQTYgtP-"
      },
      "source": [
        "###Xác định số đăng ký của các môn qua các kỳ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T32OLqKOao1J"
      },
      "outputs": [],
      "source": [
        "#các kỳ học(ở đây ví dụ một sinh có 8 kỳ học trong vòng 4 năm)\n",
        "semesters = [\"semester_1\", \"semester_2\", \"semester_3\", \"semester_4\", \"semester_5\", \"semester_6\", \"semester_7\", \"semester_8\"]\n",
        "\n",
        "count_course_semester = pd.DataFrame(columns = ['mamh'] + semesters[:])#dữ liệu chứa số đăng ký của các môn học qua các kỳ\n",
        "col_ccs = count_course_semester.columns#các cột của count_course_semester\n",
        "numberSem = 8 # số kỳ của mỗi học sinh bằng 8\n",
        "listCourse = np.unique(data_merge['mamh'])#danh sách các môn học\n",
        "\n",
        "\n",
        "#hàm course_Enroll dùng để tính số đăng ký từng môn qua các kỳ\n",
        "def course_Enroll(dataCourse, mamh, numberSem, col_ccs):\n",
        "  c = [mamh]\n",
        "  for i in range(numberSem):\n",
        "    a = dataCourse[dataCourse['soHocKy'] == (i+1)]\n",
        "    if a.shape[0]:\n",
        "      c.append(a.shape[0])\n",
        "    else: \n",
        "      c.append(0)\n",
        "\n",
        "  return pd.Series(c, index = col_ccs)\n",
        "for i in listCourse:\n",
        "  row = course_Enroll(data_merge[data_merge['mamh'] == i], i, numberSem, col_ccs)\n",
        "  count_course_semester = count_course_semester.append(row, ignore_index= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Which semester is more suitable for taking this course?\n",
        "$T_t(c,t) = \\frac{Log(Num(c,t))}{Max_{t' \\in T}(Log(Num(c,t')))}$ <br>\n",
        "##Which courses are popular now?\n",
        "$T_p(c,t) = \\frac{Log(Num(c,t))}{Max_{c' \\in C}(Log(Num(c',t)))}$\n",
        "##The final Timing based Score:\n",
        "$TS(c,t) = 2 \\times \\frac{T_t(c,t) \\times T_p(c,t)}{T_t(c,t) + T_p(c,t)}$"
      ],
      "metadata": {
        "id": "fu97us3UdnwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate T_t\n",
        "T_t = count_course_semester.copy()\n",
        "T_t.index = count_course_semester['mamh']\n",
        "T_t = T_t.drop('mamh', axis = 1)\n",
        "T_t = T_t + 1#evade divide Log(0)\n",
        "T_t = np.log(T_t.astype(float))\n",
        "for i in range(T_t.shape[0]):\n",
        "  maxx = max(T_t.iloc[i])\n",
        "  T_t.iloc[i] = (T_t.iloc[i]/maxx)\n",
        "#calculate T_p\n",
        "T_p = count_course_semester.copy()\n",
        "T_p.index = count_course_semester['mamh']\n",
        "T_p = T_p.drop('mamh', axis = 1)\n",
        "T_p = T_p + 1#evade divide Log(0)\n",
        "T_p = np.log(T_p.astype(float))\n",
        "for i in range(T_p.shape[1]):\n",
        "  maxx = max(T_p[T_p.columns[i]])\n",
        "  T_p.iloc[:,i] = (T_t.iloc[:,i]/maxx)\n",
        "\n",
        "#calculate TS\n",
        "\n",
        "TS = (T_t*T_p)/(T_t + T_p)\n",
        "TS['mssv'] = TS.index\n",
        "TS.to_excel('TS.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "aLV5gn6_g86m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grade-based Score\n",
        "##To predict the grade of a course in adjacent semester for a student\n",
        "$C_{S,S_{s}}$ denotes the courses that are enrolled by both students S and $S_s$"
      ],
      "metadata": {
        "id": "mVpXLoJ3Rw5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#course grade of each student\n",
        "\n",
        "courses = np.unique(data_train['mamh'])\n",
        "#train\n",
        "course_grade_train = pd.DataFrame(0, index = student_train, columns = courses)#điểm từng môn của của từng học sinh train\n",
        "for i in range(course_grade_train.shape[0]):\n",
        "  print(i)\n",
        "  for j in range(course_grade_train.shape[1]):\n",
        "    d = data_train[(data_train['mssv'] == course_grade_train.index[i]) & (data_train['mamh'] == course_grade_train.columns[j])]\n",
        "    if not d.empty:\n",
        "      course_grade_train.iloc[i,j] = d.loc[d.index[0], 'diem']\n",
        "#test\n",
        "course_grade_test = pd.DataFrame(0, index = student_test, columns = courses)#điểm từng môn của của từng học sinh test\n",
        "for i in range(course_grade_test.shape[0]):\n",
        "  print(i)\n",
        "  for j in range(course_grade_test.shape[1]):\n",
        "    d = data_test[(data_test['mssv'] == course_grade_test.index[i]) & (data_test['mamh'] == course_grade_test.columns[j])]\n",
        "    if not d.empty:\n",
        "      course_grade_test.iloc[i,j] = d.loc[d.index[0], 'diem']\n"
      ],
      "metadata": {
        "id": "lZ8I038OXVKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIOFpDPCQQid"
      },
      "source": [
        "###GPA of each student in per semester"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFeYEc5CFr8z"
      },
      "outputs": [],
      "source": [
        "#Tính số chỉ từng kỳ của\n",
        "terms = [\"2013_1\", \"2013_2\", \"2014_1\", \"2014_2\", \"2015_1\", \"2015_2\", \"2016_1\", \"2016_2\"]#các kỳ học\n",
        "years = [2013, 2014, 2015, 2016]\n",
        "ectsOfTerms = pd.DataFrame(columns = terms)#số tín chỉ theo của kỳ của từng học sinh\n",
        "\n",
        "#hàm này dùng để tính số tín chỉ của từng học sinh\n",
        "def ects(dataStudent, years, terms):\n",
        "  e = []\n",
        "  for i in years:\n",
        "    a = dataStudent[(dataStudent['namhoc'] == i) & (dataStudent['hocky'] == 1)]\n",
        "    b = dataStudent[(dataStudent['namhoc'] == i) & (dataStudent['hocky'] == 2)]\n",
        "    if a.shape[0]:\n",
        "      e.append(sum(a['sotc']))\n",
        "    else: \n",
        "      e.append(0)\n",
        "    if b.shape[0]:\n",
        "      e.append(sum(b['sotc']))\n",
        "    else: \n",
        "      e.append(0)\n",
        "  return pd.Series(e, index = terms)\n",
        "\n",
        "for i in listStudent:\n",
        "  row = ects(data_merge[data_merge['mssv'] == i], years, terms)\n",
        "  ectsOfTerms = ectsOfTerms.append(row, ignore_index=True)\n",
        "ectsOfTerms.insert(0,'mssv', listStudent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IULrhnOUYIvI"
      },
      "outputs": [],
      "source": [
        "gpaTerms = pd.DataFrame(columns = terms)#điểm trung bình của từng học sinh theo cách kỳ học\n",
        "\n",
        "#hàm này dùng để tính điểm trung bình từng kỳ của các học sinh\n",
        "def gpa(dataStudent, years, terms, ectsStudent):\n",
        "#ectsStudent là số tín chỉ các kỳ của một học sinh s\n",
        "  g = []\n",
        "  Sum = 0\n",
        "  for i in range(len(years)):\n",
        "    a = dataStudent[(dataStudent['namhoc'] == years[i]) & (dataStudent['hocky'] == 1)]\n",
        "    b = dataStudent[(dataStudent['namhoc'] == years[i]) & (dataStudent['hocky'] == 2)]\n",
        "    #kỳ 1\n",
        "    if a.shape[0]:\n",
        "      Sum += sum(a['sotc']*a['diem'])\n",
        "      g.append(round(Sum/sum(ectsStudent.iloc[0,1:i*2 + 2]),2))\n",
        "    else: \n",
        "      g.append(round(Sum/sum(ectsStudent.iloc[0,1:i*2 + 2]),2))\n",
        "    #kỳ 2\n",
        "    if b.shape[0]:\n",
        "      Sum += sum(b['sotc']*b['diem'])\n",
        "      g.append(round(Sum/sum(ectsStudent.iloc[0,1:i*2 + 3]),2))\n",
        "    else: \n",
        "      g.append(round(Sum/sum(ectsStudent.iloc[0,1:i*2 + 3]),2))\n",
        "  return pd.Series(g, index = terms)\n",
        "\n",
        "for i in listStudent:\n",
        "  row = gpa(data_merge[data_merge['mssv'] == i], years, terms, ectsOfTerms[ectsOfTerms['mssv'] == i])\n",
        "  gpaTerms = gpaTerms.append(row, ignore_index=True)\n",
        "gpaTerms.insert(0,'mssv', listStudent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPA of student for train and test"
      ],
      "metadata": {
        "id": "yEc5DXATb50a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "gpaTerms_train = gpaTerms[gpaTerms['mssv'].isin(student_train)]\n",
        "gpaTerms_train.index = gpaTerms_train['mssv']\n",
        "gpaTerms_train = gpaTerms_train.drop('mssv', axis = 1)\n",
        "gpa_train = pd.DataFrame(0, index = student_train, columns = ['average'])\n",
        "\n",
        "for i in range(student_train.shape[0]):\n",
        "  gpa_train.iloc[i,0] = gpaTerms_train.loc[student_train[i]].mean(skipna=True)\n",
        "\n",
        "#test\n",
        "gpaTerms_test = gpaTerms[gpaTerms['mssv'].isin(student_test)]\n",
        "gpaTerms_test.index = gpaTerms_test['mssv']\n",
        "gpaTerms_test = gpaTerms_test.drop('mssv', axis = 1)\n",
        "gpa_test = pd.DataFrame(0, index = student_test, columns = ['average'])\n",
        "\n",
        "for i in range(student_test.shape[0]):\n",
        "  gpa_test.iloc[i,0] = gpaTerms_test.loc[student_test[i],:'2015_2'].mean(skipna=True)\n",
        "gpa_test = gpa_test.dropna()"
      ],
      "metadata": {
        "id": "jAgMRWSsVodW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#just can predict grade of students who had previour grade\n",
        "#Therefore I remove freshmans "
      ],
      "metadata": {
        "id": "OsWHsujwoy1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "course_grade_test = pd.read_excel('course_grade_test.xlsx')\n",
        "course_grade_train = pd.read_excel('course_grade_train.xlsx')"
      ],
      "metadata": {
        "id": "lw3qyJMKK-IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_predict = gpa_test.index # danh sách cách học sinh có thể dự đoán điểm vì có dữ liệu điểm từ kỳ trc\n",
        "course_grade_test = course_grade_test[course_grade_test['mssv'].isin(student_predict)]"
      ],
      "metadata": {
        "id": "LphMqoscjzjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$sim(S,S_s) = \\frac{\\sum_{i \\in C_{S,S_{s}}}(g_{si} - mean(g_{si}))(g_{s_{s}i} - mean(g_{s_{s}i}))} {\\sqrt{\\sum_{i \\in C_{S,S_{s}}}(g_{si} - mean(g_{si}))^2} \\sqrt{\\sum_{i \\in C_{S,S_{s}}}(g_{s_{s}i} - mean(g_{s_{s}i}))^2}}$"
      ],
      "metadata": {
        "id": "kreZXJFRwCvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "course_grade_train.index = course_grade_train['mssv']\n",
        "course_grade_train = course_grade_train.drop('mssv', axis = 1)#xóa côt mssv\n",
        "course_grade_test.index = course_grade_test['mssv']\n",
        "course_grade_test = course_grade_test.drop('mssv', axis = 1)"
      ],
      "metadata": {
        "id": "gldxl5GTqzf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sim_grade = pd.DataFrame(0, index = student_predict, columns = student_train)\n",
        "for i in range(Sim_grade.shape[0]):\n",
        "  print(i)\n",
        "  for j in range(Sim_grade.shape[1]):\n",
        "    a = course_grade_test.loc[Sim_grade.index[i], :]*course_grade_train.loc[Sim_grade.columns[j], :]\n",
        "    common = a.index[a != 0 ].tolist()\n",
        "    if common:\n",
        "      g_si = course_grade_test.loc[Sim_grade.index[i]] - gpa_test.loc[Sim_grade.index[i]].iloc[0]\n",
        "      g_ssi = course_grade_train.loc[Sim_grade.columns[j]] - gpa_train.loc[Sim_grade.columns[j]].iloc[0]\n",
        "      numerator = sum([(g_si.loc[t]*g_ssi.loc[t]) for t in common])\n",
        "      denominator = np.sqrt(sum([(g_si.loc[t])**2 for t in common])) * np.sqrt(sum([(g_ssi.loc[t])**2 for t in common]))\n",
        "      Sim_grade.iloc[i,j] = numerator/denominator"
      ],
      "metadata": {
        "id": "bI8v5fWk41Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sim_grade = pd.read_excel('Sim_grade.xlsx')\n",
        "Sim_grade.index = Sim_grade['mssv']\n",
        "Sim_grade = Sim_grade.drop('mssv', axis = 1)"
      ],
      "metadata": {
        "id": "JaC6uU1LRQgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####top-k trong Sim_grade\n",
        "k = 7\n",
        "\n",
        "grade_k = Sim_grade.apply(lambda row: row.nlargest(k), axis=1)\n",
        "grade_k_mssv = pd.DataFrame(0, index = grade_k.index,columns = [i for i in range(k)])#top-k similar student code of s as neighbors\n",
        "for i in range(grade_k.shape[0]):\n",
        "  count = 0\n",
        "  for j in range(grade_k.shape[1]):\n",
        "    if not pd.isna(grade_k.loc[grade_k.index[i], grade_k.columns[j]]):\n",
        "      grade_k_mssv.iloc[i,count] = grade_k.columns[j]\n",
        "      count +=1\n",
        "\n"
      ],
      "metadata": {
        "id": "a6b1qZylONbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Điểm trung bình của từng môn học\n",
        "avg_courses = pd.DataFrame(0, index = ['average'], columns = course_grade_train.columns)\n",
        "numStudent = course_grade_train.shape[0] + course_grade_test.shape[0]\n",
        "for i in range(avg_courses.shape[1]):\n",
        "\n",
        "  Sum_train = sum(course_grade_train.loc[:,avg_courses.columns[i]])\n",
        "  student0_train = course_grade_train[avg_courses.columns[i]].value_counts()[0.0] # những học sinh không có dữ liệu trong kỳ đó\n",
        "\n",
        "  Sum_test = sum(course_grade_test.loc[:,avg_courses.columns[i]])\n",
        "  student0_test = course_grade_test[avg_courses.columns[i]].value_counts()[0.0]\n",
        "  \n",
        "  avg_courses.iloc[0,i] = (Sum_train + Sum_test)/(numStudent - student0_train - student0_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iyop3ahM9_P8",
        "outputId": "91f813df-ad28-4a22-cb54-df7dbea29a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-557d9a5c60f2>:12: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  avg_courses.iloc[0,i] = (Sum_train + Sum_test)/(numStudent - student0_train - student0_test)\n",
            "<ipython-input-57-557d9a5c60f2>:12: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  avg_courses.iloc[0,i] = (Sum_train + Sum_test)/(numStudent - student0_train - student0_test)\n",
            "<ipython-input-57-557d9a5c60f2>:12: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  avg_courses.iloc[0,i] = (Sum_train + Sum_test)/(numStudent - student0_train - student0_test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azAmmDUXFKKh",
        "outputId": "39b9946c-c517-49c4-8c38-5188fd46f30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.697297263789821"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPDM4nQJpRb6"
      },
      "source": [
        "###Điểm trung bình của tất cả các khóa học của tất cả các học sinh trong một kỳ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se7py3U_Tph8"
      },
      "outputs": [],
      "source": [
        "gpaTerms2 = gpaTerms.copy()\n",
        "gpaTerms2.replace(to_replace = np.nan, value = 0, inplace =True)\n",
        "\n",
        "# avgAll điểm trung bình của tất cả các học sinh trong một kỳ là\n",
        "avgAll_semester = []\n",
        "numberStudents = len(listStudent)\n",
        "for i in range(len(terms)):\n",
        "\n",
        "  Sum = sum(gpaTerms2[terms[i]])\n",
        "  student0 = gpaTerms2[terms[i]].value_counts()[0.0] # những học sinh không có dữ liệu trong kỳ đó\n",
        "  avgAll_semester.append(round(Sum/(numberStudents-student0),2))\n",
        "\n",
        "avgAll = sum(avgAll_semester)/len(avgAll_semester)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####top-k trong Sim_grade(grade_k_mssv)\n",
        "####Điểm trung bình của từng học sinh(gpa_train, gpa_test)\n",
        "####Điểm trung bình của từng môn học(avg_courses)\n",
        "####điểm trung bình tất cả(avgAll)"
      ],
      "metadata": {
        "id": "Z4XQNnPyBDIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$g_{sc} = b_{sc} + \\frac {\\sum_{S_s \\in S_{s,k}}(g_{S_{s}C} - b_{S_{s}C}) \\times sim(S,S_{s})} {\\sum_{S_{s} \\in S_{s,k}}sim(S,S_s)}$"
      ],
      "metadata": {
        "id": "HibqQyqGL4Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##compute b_sc\n",
        "##b_sc = GPA(s) + average(c) - avgAll\n",
        "b_sc_train = pd.DataFrame(0, index = course_grade_train.index, columns = course_grade_train.columns)\n",
        "\n",
        "for i in range(b_sc_train.shape[0]):\n",
        "  for j in range(b_sc_train.shape[1]):\n",
        "    # if course_grade_train.loc[b_sc_train.index[i], b_sc_train.columns[j]]:# nếu môn nào học sinh không tham gia thì không phải tính độ chênh lệch\n",
        "      b_sc_train.iloc[i,j] = gpa_train.loc[b_sc_train.index[i], 'average'] + avg_courses.loc[avg_courses.index[0], b_sc_train.columns[j]] - avgAll\n",
        "\n",
        "b_sc_test = pd.DataFrame(0, index = course_grade_test.index, columns = course_grade_test.columns)\n",
        "\n",
        "for i in range(b_sc_test.shape[0]):\n",
        "  for j in range(b_sc_test.shape[1]):\n",
        "    # if course_grade_test.loc[b_sc_test.index[i], b_sc_test.columns[j]]:# nếu môn nào học sinh không tham gia thì không phải tính độ chênh lệch\n",
        "      b_sc_test.iloc[i,j] = gpa_test.loc[b_sc_test.index[i], 'average'] + avg_courses.loc[avg_courses.index[0], b_sc_test.columns[j]] - avgAll"
      ],
      "metadata": {
        "id": "dupQMR0rFzqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute g_sc\n",
        "g_sc = pd.DataFrame(0, index = course_grade_test.index, columns = course_grade_test.columns)\n",
        "for i in range(g_sc.shape[0]):\n",
        "  print(i)\n",
        "  for j in range(g_sc.shape[1]):\n",
        "    numerator = sum([(course_grade_train.loc[t, g_sc.columns[j]] - b_sc_train.loc[t, g_sc.columns[j]])*(Sim_grade.loc[g_sc.index[i], t]) for t in grade_k_mssv.loc[g_sc.index[i]]])\n",
        "    denominator = sum([(Sim_grade.loc[g_sc.index[i], t]) for t in grade_k_mssv.loc[g_sc.index[i]]])\n",
        "    g_sc.iloc[i,j] = b_sc_test.loc[g_sc.index[i], g_sc.columns[j]] + numerator/denominator\n"
      ],
      "metadata": {
        "id": "9WPO4hMZRMWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(g_sc.shape[0]):\n",
        "  g_sc.iloc[i] = g_sc.iloc[i]/(max(g_sc.iloc[i]))"
      ],
      "metadata": {
        "id": "5PItuwtUhcA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_sc2 = pd.DataFrame(0, index = course_grade_test.index, columns = course_grade_test.columns)\n",
        "for i in range(g_sc2.shape[0]):\n",
        "  print(i)\n",
        "  for j in range(g_sc2.shape[1]):\n",
        "    numerator = sum([(course_grade_train.loc[t, g_sc2.columns[j]])*(Sim_grade.loc[g_sc2.index[i], t]) for t in grade_k_mssv.loc[g_sc2.index[i]]])\n",
        "    denominator = sum([(Sim_grade.loc[g_sc2.index[i], t]) for t in grade_k_mssv.loc[g_sc2.index[i]]])\n",
        "    g_sc2.iloc[i,j] = numerator/denominator\n",
        "    "
      ],
      "metadata": {
        "id": "CwtD5SdrixpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_sc['mssv'] = g_sc.index\n",
        "g_sc2['mssv'] = g_sc2.index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4e4T-ppm_X-",
        "outputId": "c590a6a9-c327-409b-e0d0-2a361ad2a812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-105-2a1c1344de99>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  g_sc2['mssv'] = g_sc2.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_sc.to_excel('GS.xlsx', index = False)\n",
        "g_sc2.to_excel('GS_replace.xlsx', index = False)"
      ],
      "metadata": {
        "id": "BTATeqg5nJ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr65WQL9xq-Q"
      },
      "source": [
        "###Điểm trung bình một môn trong một học kỳ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tscUX42ftZHM"
      },
      "outputs": [],
      "source": [
        "# courseTerms Điểm trung bình một môn trong một học kỳ\n",
        "courseTerms = pd.DataFrame(columns = ['mamh'] + terms[:])\n",
        "listCourse = np.unique(data_merge['mamh'])#danh sách các môn học\n",
        "courseTerms_column = courseTerms.columns\n",
        "def avgCourse(dataCourse, terms, mamh, years, courseTerms_column):\n",
        "  av = [mamh]\n",
        "  Sum = 0\n",
        "  Count = 1 #Biến đếm số đăng ký của môn cho bằng 1 vì để chánh chia cho 0\n",
        "  for i in range(len(years)):\n",
        "    a = dataCourse[(dataCourse['namhoc'] == years[i]) & (dataCourse['hocky'] == 1)]\n",
        "    b = dataCourse[(dataCourse['namhoc'] == years[i]) & (dataCourse['hocky'] == 2)]\n",
        "    if a.shape[0]:\n",
        "      Sum += sum(a['diem'])\n",
        "      Count += a.shape[0]\n",
        "      av.append(round(Sum/Count,2))\n",
        "    else:\n",
        "      av.append(round(Sum/Count,2))\n",
        "    if b.shape[0]:\n",
        "      Sum += sum(b['diem'])\n",
        "      Count += b.shape[0]\n",
        "      av.append(round(Sum/Count,2))\n",
        "    else:\n",
        "      av.append(round(Sum/Count,2))\n",
        "  return pd.Series(av, index = courseTerms_column)\n",
        "for i in listCourse:\n",
        "  row = avgCourse(data_merge[data_merge['mamh'] == i], terms, i, years, courseTerms_column)\n",
        "  courseTerms = courseTerms.append(row, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGr_fAQWc1Yb"
      },
      "source": [
        "###DataFrame khoa của từng học sinh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_R_NETQPBou"
      },
      "outputs": [],
      "source": [
        "cateStudent = pd.DataFrame(columns=['mssv','khoa'])#đây là dữ liệu chưa khoa của từng học sinh\n",
        "for i in range(listStudent.shape[0]):\n",
        "  k = data_merge[data_merge['mssv'] == data_merge.loc[i,'mssv']].khoa.iloc[0]\n",
        "  row = pd.Series([listStudent[i], k], index = ['mssv', 'khoa'])\n",
        "  cateStudent = cateStudent.append(row, ignore_index = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdds0jb3Lg66"
      },
      "source": [
        "#Trong project có 3 feature dùng để đánh giá có nên đăng ký 1 môn học cho kỳ tiếp theo không:\n",
        "##1 Interest Score gồm có:\n",
        "### số môn đăng ký của từng khoa của từng học sinh(enrInFac)\n",
        "### khoa của từng học sinh(cateStudent)\n",
        "##2 Timing and popularity based Score gồm có:\n",
        "###Xác định số đăng ký của các môn qua các kỳ(count_course_semester)\n",
        "##3 Grade Score gồm có\n",
        "###điểm trung bình của học sinh theo từng kỳ(gpaTerms)\n",
        "###Điểm trung bình của tất cả các khóa học của tất cả các học sinh trong một kỳ(avgAll)\n",
        "###Điểm trung bình một môn trong một học kỳ(courseTerms)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tổng cộng có 4 năm 8 kỳ vì vậy lấy 3 năm đầu làm tập train còn năm cuối cùng làm tập test"
      ],
      "metadata": {
        "id": "vIo-e11uzNh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Danh sách môn học dự đoán\n",
        "y_pred = [\"Math\", \"Physics\", \"Chemistry\", \"Biology\"]\n",
        "\n",
        "# Danh sách môn học thực tế\n",
        "y_true = [\"Math\", \"Physics\", \"English\", \"Biology\"]\n",
        "\n",
        "# Tính toán F1 score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# In kết quả\n",
        "print(\"F1 score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekn08VSaB4s-",
        "outputId": "371195f8-f228-421c-95af-7533093846e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.75\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUccWjBiO8MgAMcpLFkm9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}